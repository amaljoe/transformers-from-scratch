{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed2d9728-f44d-43e6-a674-b8056e9b86fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "/lib64/libc.so.6: version `GLIBC_2.32' not found (required by /home/compiling-ganesh/24m0797/workspace/transformers-from-scratch/.venv/lib/python3.12/site-packages/flash_attn_2_cuda.cpython-312-x86_64-linux-gnu.so)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mflash_attn\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mflash attn ok\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/transformers-from-scratch/.venv/lib/python3.12/site-packages/flash_attn/__init__.py:3\u001b[39m\n\u001b[32m      1\u001b[39m __version__ = \u001b[33m\"\u001b[39m\u001b[33m2.7.3\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mflash_attn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mflash_attn_interface\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      4\u001b[39m     flash_attn_func,\n\u001b[32m      5\u001b[39m     flash_attn_kvpacked_func,\n\u001b[32m      6\u001b[39m     flash_attn_qkvpacked_func,\n\u001b[32m      7\u001b[39m     flash_attn_varlen_func,\n\u001b[32m      8\u001b[39m     flash_attn_varlen_kvpacked_func,\n\u001b[32m      9\u001b[39m     flash_attn_varlen_qkvpacked_func,\n\u001b[32m     10\u001b[39m     flash_attn_with_kvcache,\n\u001b[32m     11\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/transformers-from-scratch/.venv/lib/python3.12/site-packages/flash_attn/flash_attn_interface.py:15\u001b[39m\n\u001b[32m     13\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mflash_attn_triton_amd\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m interface_fa \u001b[38;5;28;01mas\u001b[39;00m flash_attn_gpu\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mflash_attn_2_cuda\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mflash_attn_gpu\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# isort: on\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmaybe_contiguous\u001b[39m(x):\n",
      "\u001b[31mImportError\u001b[39m: /lib64/libc.so.6: version `GLIBC_2.32' not found (required by /home/compiling-ganesh/24m0797/workspace/transformers-from-scratch/.venv/lib/python3.12/site-packages/flash_attn_2_cuda.cpython-312-x86_64-linux-gnu.so)"
     ]
    }
   ],
   "source": [
    "import flash_attn\n",
    "print(\"flash attn ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff265a84-cc4c-4ddf-9cf7-fc3ae28afe3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./.cache/flash_attn-2.7.3.tar.gz\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: torch in ./.venv/lib/python3.12/site-packages (from flash_attn==2.7.3) (2.8.0)\n",
      "Requirement already satisfied: einops in ./.venv/lib/python3.12/site-packages (from flash_attn==2.7.3) (0.8.1)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.12/site-packages (from torch->flash_attn==2.7.3) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./.venv/lib/python3.12/site-packages (from torch->flash_attn==2.7.3) (4.15.0)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.12/site-packages (from torch->flash_attn==2.7.3) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./.venv/lib/python3.12/site-packages (from torch->flash_attn==2.7.3) (1.14.0)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.12/site-packages (from torch->flash_attn==2.7.3) (3.6)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.12/site-packages (from torch->flash_attn==2.7.3) (3.1.6)\n",
      "Requirement already satisfied: fsspec in ./.venv/lib/python3.12/site-packages (from torch->flash_attn==2.7.3) (2025.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in ./.venv/lib/python3.12/site-packages (from torch->flash_attn==2.7.3) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in ./.venv/lib/python3.12/site-packages (from torch->flash_attn==2.7.3) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in ./.venv/lib/python3.12/site-packages (from torch->flash_attn==2.7.3) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in ./.venv/lib/python3.12/site-packages (from torch->flash_attn==2.7.3) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in ./.venv/lib/python3.12/site-packages (from torch->flash_attn==2.7.3) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in ./.venv/lib/python3.12/site-packages (from torch->flash_attn==2.7.3) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in ./.venv/lib/python3.12/site-packages (from torch->flash_attn==2.7.3) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in ./.venv/lib/python3.12/site-packages (from torch->flash_attn==2.7.3) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in ./.venv/lib/python3.12/site-packages (from torch->flash_attn==2.7.3) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in ./.venv/lib/python3.12/site-packages (from torch->flash_attn==2.7.3) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in ./.venv/lib/python3.12/site-packages (from torch->flash_attn==2.7.3) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in ./.venv/lib/python3.12/site-packages (from torch->flash_attn==2.7.3) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in ./.venv/lib/python3.12/site-packages (from torch->flash_attn==2.7.3) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in ./.venv/lib/python3.12/site-packages (from torch->flash_attn==2.7.3) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.4.0 in ./.venv/lib/python3.12/site-packages (from torch->flash_attn==2.7.3) (3.4.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.12/site-packages (from sympy>=1.13.3->torch->flash_attn==2.7.3) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.12/site-packages (from jinja2->torch->flash_attn==2.7.3) (3.0.3)\n",
      "Building wheels for collected packages: flash_attn\n",
      "  Building wheel for flash_attn (pyproject.toml) ... \u001b[?25l|"
     ]
    }
   ],
   "source": [
    "pip install .cache/flash_attn-2.7.3.tar.gz --no-build-isolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09b15e3f-491f-4213-abe0-ee4f3ef37dee",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "This modeling file requires the following packages that were not found in your environment: flash_attn. Run `pip install flash_attn`",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Load model directly\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoModel\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m model = \u001b[43mAutoModel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdeepseek-ai/DeepSeek-OCR\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mauto\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/transformers-from-scratch/.venv/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py:524\u001b[39m, in \u001b[36m_BaseAutoModelClass.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[39m\n\u001b[32m    521\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mquantization_config\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    522\u001b[39m     _ = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mquantization_config\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m524\u001b[39m config, kwargs = \u001b[43mAutoConfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    525\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    526\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_unused_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    527\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    528\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcode_revision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcode_revision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    529\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    530\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    531\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    532\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    534\u001b[39m \u001b[38;5;66;03m# if torch_dtype=auto was passed here, ensure to pass it on\u001b[39;00m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m kwargs_orig.get(\u001b[33m\"\u001b[39m\u001b[33mtorch_dtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[33m\"\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/transformers-from-scratch/.venv/lib/python3.12/site-packages/transformers/models/auto/configuration_auto.py:981\u001b[39m, in \u001b[36mAutoConfig.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[39m\n\u001b[32m    979\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_remote_code \u001b[38;5;129;01mand\u001b[39;00m trust_remote_code:\n\u001b[32m    980\u001b[39m     class_ref = config_dict[\u001b[33m\"\u001b[39m\u001b[33mauto_map\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mAutoConfig\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m981\u001b[39m     config_class = \u001b[43mget_class_from_dynamic_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    982\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclass_ref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode_revision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcode_revision\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    983\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    984\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m os.path.isdir(pretrained_model_name_or_path):\n\u001b[32m    985\u001b[39m         config_class.register_for_auto_class()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/transformers-from-scratch/.venv/lib/python3.12/site-packages/transformers/dynamic_module_utils.py:502\u001b[39m, in \u001b[36mget_class_from_dynamic_module\u001b[39m\u001b[34m(class_reference, pretrained_model_name_or_path, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, repo_type, code_revision, **kwargs)\u001b[39m\n\u001b[32m    500\u001b[39m     code_revision = revision\n\u001b[32m    501\u001b[39m \u001b[38;5;66;03m# And lastly we get the class inside our newly created module\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m502\u001b[39m final_module = \u001b[43mget_cached_module_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    503\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    504\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodule_file\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m.py\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    505\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    506\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    507\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    508\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    509\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    510\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcode_revision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    511\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    512\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    513\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    514\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m get_class_in_module(class_name, final_module)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/transformers-from-scratch/.venv/lib/python3.12/site-packages/transformers/dynamic_module_utils.py:365\u001b[39m, in \u001b[36mget_cached_module_file\u001b[39m\u001b[34m(pretrained_model_name_or_path, module_file, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, repo_type, _commit_hash, **deprecated_kwargs)\u001b[39m\n\u001b[32m    363\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module_needed \u001b[38;5;129;01min\u001b[39;00m modules_needed:\n\u001b[32m    364\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (submodule_path / \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_needed\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.py\u001b[39m\u001b[33m\"\u001b[39m).exists():\n\u001b[32m--> \u001b[39m\u001b[32m365\u001b[39m             \u001b[43mget_cached_module_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    366\u001b[39m \u001b[43m                \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    367\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodule_needed\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m.py\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    368\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    369\u001b[39m \u001b[43m                \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    370\u001b[39m \u001b[43m                \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    371\u001b[39m \u001b[43m                \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[43m                \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    374\u001b[39m \u001b[43m                \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    375\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    376\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    377\u001b[39m             new_files.append(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_needed\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.py\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(new_files) > \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m revision \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/transformers-from-scratch/.venv/lib/python3.12/site-packages/transformers/dynamic_module_utils.py:327\u001b[39m, in \u001b[36mget_cached_module_file\u001b[39m\u001b[34m(pretrained_model_name_or_path, module_file, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, repo_type, _commit_hash, **deprecated_kwargs)\u001b[39m\n\u001b[32m    324\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m    326\u001b[39m \u001b[38;5;66;03m# Check we have all the requirements in our environment\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m modules_needed = \u001b[43mcheck_imports\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresolved_module_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[38;5;66;03m# Now we move the module inside our cached dynamic modules.\u001b[39;00m\n\u001b[32m    330\u001b[39m full_submodule = TRANSFORMERS_DYNAMIC_MODULE_NAME + os.path.sep + submodule\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/transformers-from-scratch/.venv/lib/python3.12/site-packages/transformers/dynamic_module_utils.py:182\u001b[39m, in \u001b[36mcheck_imports\u001b[39m\u001b[34m(filename)\u001b[39m\n\u001b[32m    179\u001b[39m         missing_packages.append(imp)\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_packages) > \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m182\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m    183\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThis modeling file requires the following packages that were not found in your environment: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    184\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(missing_packages)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. Run `pip install \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m.join(missing_packages)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    185\u001b[39m     )\n\u001b[32m    187\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m get_relative_imports(filename)\n",
      "\u001b[31mImportError\u001b[39m: This modeling file requires the following packages that were not found in your environment: flash_attn. Run `pip install flash_attn`"
     ]
    }
   ],
   "source": [
    "# Load mhttp://localhost:8888/lib64/libc.so.6odel directly\n",
    "from transformers import AutoModel\n",
    "model = AutoModel.from_pretrained(\"deepseek-ai/DeepSeek-OCR\", trust_remote_code=True, dtype=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce38008-0a12-4128-ad13-346f833c6bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "model_name = 'deepseek-ai/DeepSeek-OCR'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "model = AutoModel.from_pretrained(model_name, _attn_implementation='flash_attention_2', trust_remote_code=True, use_safetensors=True)\n",
    "model = model.eval().cuda().to(torch.bfloat16)\n",
    "\n",
    "# prompt = \"<image>\\nFree OCR. \"\n",
    "prompt = \"<image>\\n<|grounding|>Convert the document to markdown. \"\n",
    "image_file = 'your_image.jpg'\n",
    "output_path = 'data/'\n",
    "\n",
    "# infer(self, tokenizer, prompt='', image_file='', output_path = ' ', base_size = 1024, image_size = 640, crop_mode = True, test_compress = False, save_results = False):\n",
    "\n",
    "# Tiny: base_size = 512, image_size = 512, crop_mode = False\n",
    "# Small: base_size = 640, image_size = 640, crop_mode = False\n",
    "# Base: base_size = 1024, image_size = 1024, crop_mode = False\n",
    "# Large: base_size = 1280, image_size = 1280, crop_mode = False\n",
    "\n",
    "# Gundam: base_size = 1024, image_size = 640, crop_mode = True\n",
    "\n",
    "res = model.infer(tokenizer, prompt=prompt, image_file=image_file, output_path = output_path, base_size = 1024, image_size = 640, crop_mode=True, save_results = True, test_compress = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
